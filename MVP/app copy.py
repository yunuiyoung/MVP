from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizableTextQuery
from openai import AzureOpenAI
from azure.core.credentials import AzureKeyCredential
import json
import os
import pandas as pd # pandas ì¶”ê°€
from dotenv import load_dotenv

load_dotenv()

# --- í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (2ë‹¨ê³„ì—ì„œ ì„¤ì •í•œ ê°’ê³¼ ë™ì¼í•˜ê²Œ) ---
# ì´ ë¶€ë¶„ì€ ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ê±°ë‚˜, í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
service_name = os.getenv("AZURE_SEARCH_SERVICE_NAME")
index_name = os.getenv("AZURE_SEARCH_INDEX_NAME")
endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
key = os.getenv("AZURE_SEARCH_ADMIN_KEY") # ì‹¤ì œ í‚¤ë¡œ ë³€ê²½ í•„ìš”

azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT") # ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½ í•„ìš”
azure_openai_key = os.getenv("AZURE_OPENAI_API_KEY") # ì‹¤ì œ í‚¤ë¡œ ë³€ê²½ í•„ìš”
embedding_model_name = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME")
llm_model_name = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME") # ë°°í¬ëœ LLM ëª¨ë¸ ì´ë¦„ (ì˜ˆ: gpt-4, gpt-35-turbo)

# í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´
if "YOUR_" in key or "YOUR_" in azure_openai_endpoint or "YOUR_" in azure_openai_key:
    print("ğŸš¨ ê²½ê³ : Azure ì„œë¹„ìŠ¤ í‚¤ ë˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ìœ„ ì½”ë“œì˜ 'YOUR_...' ë¶€ë¶„ì„ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜, í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    # exit() # ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ì¢…ë£Œí•˜ê±°ë‚˜ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬

# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = AzureOpenAI(
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_key,
    api_version="2024-12-01-preview"
)

# ì„ë² ë”© ìƒì„± í•¨ìˆ˜
def generate_embeddings(text):
    try:
        response = openai_client.embeddings.create(
            input=text,
            model=embedding_model_name
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   Azure OpenAI ì—”ë“œí¬ì¸íŠ¸, í‚¤, ëª¨ë¸ ë°°í¬ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

# Azure AI Search í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
search_client = SearchClient(endpoint=endpoint,
                             index_name=index_name,
                             credential=AzureKeyCredential(key)
)

def estimate_development_effort(new_project_description: str):
    """
    ì‹ ê·œ í”„ë¡œì íŠ¸ ìƒì„¸ ìš”ê±´ì„ ë°”íƒ•ìœ¼ë¡œ ê°œë°œ ê³µìˆ˜(MM)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    print("âœ¨ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ìš”ê±´ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")

    # # 1. ì‹ ê·œ ìš”ê±´ ë²¡í„°í™”
    # new_description_vector = generate_embeddings(new_project_description)
    # if new_description_vector is None:
    #     return None
    # print("âœ… ì‹ ê·œ ìš”ê±´ ë²¡í„°í™” ì™„ë£Œ.")

    # 2. Azure AI Searchì—ì„œ ìœ ì‚¬ í”„ë¡œì íŠ¸ ê²€ìƒ‰ (RAG)
    vector_query = VectorizableTextQuery(
        text=new_project_description,
        k_nearest_neighbors=3, # ìµœìƒìœ„ 3ê°œ í”„ë¡œì íŠ¸ íƒìƒ‰
        fields="text_vector"
    )
    
    results = search_client.search(
        search_text=None, # ë²¡í„° ê²€ìƒ‰ë§Œ ìˆ˜í–‰í•˜ë¯€ë¡œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ì€ ë¹„í™œì„±í™”
        vector_queries=[vector_query],
        # select=["project_name", "description", "dev_parts_effort"],
        top=3 # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ê°€ì ¸ì˜¤ê¸°
    )

    similar_projects = []
    for i, result in enumerate(results):
        similar_projects.append({
            "project_name": result["ProjectName"],
            "description": result["chunk"],
            'ProjectID': result["ProjectID"],
            'dev_parts_effort':{ 
                'APILink_MM': result["APILink_MM"], 
                'KOS_Order_MM': result["KOS_Order_MM"],
                'KOS_Con_MM': result['KOS_Con_MM'],
                'Bill_MM': result["Bill_MM"],
                'APP_MM': result["APP_MM"],
                'MEIN_MM': result["MEIN_MM"],
            }
        })
        print(f"ğŸ” ìœ ì‚¬ í”„ë¡œì íŠ¸ ë°œê²¬ ({i+1}ìœ„): {result['ProjectName']}")

    if not similar_projects:
        print("âš ï¸ ìœ ì‚¬í•œ ê³¼ê±° í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì¶”ì •ì¹˜ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
        # ìœ ì‚¬ í”„ë¡œì íŠ¸ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ëŒ€ì²´
        context_str = "ê³¼ê±° í”„ë¡œì íŠ¸ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ OTT ìš”ê¸ˆì œ ê°œë°œ íŒŒíŠ¸ë³„ ê³µìˆ˜ ì˜ˆì¸¡ì„ ì‹œë„í•©ë‹ˆë‹¤."
    else:
        context_str = "ë‹¤ìŒì€ ìœ ì‚¬í•œ ê³¼ê±° í”„ë¡œì íŠ¸ë“¤ì˜ ì •ë³´ì…ë‹ˆë‹¤:\n\n"
        for project in similar_projects:
            context_str += f"### í”„ë¡œì íŠ¸ ì´ë¦„: {project['project_name']}\n"
            context_str += f"ì„¤ëª…: {project['description']}\n"
            context_str += "ê³¼ê±° ê°œë°œ ê³µìˆ˜ (MM):\n"
            for part, effort in project['dev_parts_effort'].items():
                context_str += f"  - {part}: {effort} MM\n"
            context_str += "\n"
    
    # 3. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
    ë‹¹ì‹ ì€ KT IPTV ìš”ê¸ˆì œ ê°œë°œ ê³µìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ì˜ ìƒì„¸ ìš”ê±´ê³¼ ìœ ì‚¬í•œ ê³¼ê±° í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬, ê° ê°œë°œ íŒŒíŠ¸ë³„ í•„ìš”í•œ ê°œë°œ ê³µìˆ˜(MM)ë¥¼ ë§¤ìš° ì •í™•í•˜ê²Œ ì‚°ì •í•´ì£¼ì„¸ìš”.
    
    ---
    
    **ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ìƒì„¸ ìš”ê±´:**
    {new_project_description}
    
    ---
    
    **ìœ ì‚¬í•œ ê³¼ê±° í”„ë¡œì íŠ¸ ì •ë³´:**
    {context_str}
    
    ---
    
    **ìš”ì²­ ì‚¬í•­:**
    1.  ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ ê°œë°œ íŒŒíŠ¸ë“¤ì˜ ê³µìˆ˜(MM)ë¥¼ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”: í”„ë¡ íŠ¸ì—”ë“œ, ë°±ì—”ë“œ, QA, ë””ìì¸, ê¸°íš.
    2. ê³µìˆ˜ ì˜ˆì¸¡ì— ëŒ€í•œ ì´ìœ ë„ ê·¼ê±°ë¥¼ ë“¤ì–´ì„œ ë…¼ë¦¬ì ìœ¼ë¡œ ì‘ì„±í•´ì•¼í•˜ê³ , ì´ë¥¼ 'reason' ì— í‘œì‹œí•´ì•¼í•œë‹¤.
    2.  ê° íŒŒíŠ¸ë³„ ê³µìˆ˜(MM)ëŠ” ì •ìˆ˜ ê°’ìœ¼ë¡œ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”.
    3.  ì˜ˆì¸¡ ê²°ê³¼ëŠ” JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    4.  JSON í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:
        ```json
        {{
            "KOS_Order_MM": <ì˜ˆì¸¡ MM>,
            "KOS_Con_MM": <ì˜ˆì¸¡ MM>,
            "APILink_MM": <ì˜ˆì¸¡ MM>,
            "Bill_MM": <ì˜ˆì¸¡ MM>,
            "APP_MM": <ì˜ˆì¸¡ MM>,
            "MEIN_MM": <ì˜ˆì¸¡ MM>,
            "reason": <ì˜ˆì¸¡ ê·¼ê±°>
        }}
        ```
    """

    print("ğŸ’¬ LLMì—ê²Œ ê³µìˆ˜ ì˜ˆì¸¡ì„ ìš”ì²­ ì¤‘ì…ë‹ˆë‹¤...")
    # 4. LLM í˜¸ì¶œ
    try:
        INSTRUCTION = """\
ë„ˆëŠ” ê°œë°œ ê³µìˆ˜ ì¸¡ì •ì— ëŒ€í•œ ì „ë¬¸ê°€ì•¼. ê°œë°œ ê³µìˆ˜ ê´€ë ¨í•´ì„œ ë…¼ë¦¬ì ì¸ ì‚¬ê³ ë¥¼ í•˜ë©´ì„œ ë‹µë³€ì„ ì¤˜ì•¼í•´
"""
        response = openai_client.chat.completions.create(
            model=llm_model_name,
            messages=[
                {"role": "system", "content": "You are a helpful AI assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7, # ì°½ì˜ì„± ì¡°ì ˆ (0.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¼ê´€ì , 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì°½ì˜ì )
            response_format={"type": "json_object"} # JSON ì‘ë‹µì„ ê°•ì œ
        )
        llm_output = response.choices[0].message.content
        predicted_effort = json.loads(llm_output)
        print("ğŸ‰ ê³µìˆ˜ ì˜ˆì¸¡ ì™„ë£Œ!")
        return predicted_effort

    except json.JSONDecodeError as e:
        print(f"âŒ LLM ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   LLMì´ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. LLM ì‘ë‹µ:", llm_output)
        return None
    except Exception as e:
        print(f"âŒ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   Azure OpenAI ì—”ë“œí¬ì¸íŠ¸, í‚¤, ëª¨ë¸ ë°°í¬ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None


def display_effort_table(predicted_effort):
    """
    ì˜ˆì¸¡ëœ ê³µìˆ˜ë¥¼ Markdown í…Œì´ë¸”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    if not predicted_effort:
        print("\nê³µìˆ˜ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return

    print("\n--- ğŸ“Š ì˜ˆì¸¡ëœ ê°œë°œ ê³µìˆ˜ (MM) ---")
    print("| ê°œë°œ íŒŒíŠ¸ | ì˜ˆì¸¡ ê³µìˆ˜ (MM) |")
    print("|-----------|----------------|")
    for part, effort in predicted_effort.items():
        if part != "reason":
            print(f"| {part:<10} | {effort:<14} |")
    print("---------------------------------")
    print(f"ê³µìˆ˜ ì˜ˆì¸¡ ê·¼ê±°\n : {predicted_effort['reason']}")


# --- í”„ë¡œê·¸ë¨ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹ ê·œ í”„ë¡œì íŠ¸ ìš”ê±´ ì…ë ¥
    new_project_req = """
    ìƒˆë¡œìš´ OTT ì„œë¹„ìŠ¤ 'Wrtn TV'ë¥¼ IPTV ìš”ê¸ˆì œì— ì¶”ê°€ ì—°ë™í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.
    ì£¼ìš” ê¸°ëŠ¥ì€ ì‚¬ìš©ì ë¡œê·¸ì¸ ì—°ë™, ì½˜í…ì¸  íƒìƒ‰ (VOD ë° ë¼ì´ë¸Œ ì±„ë„), ê°œì¸í™” ì¶”ì²œ, ì‹œì²­ ì´ë ¥ ë™ê¸°í™”ì…ë‹ˆë‹¤.
    ê¸°ì¡´ TVING ì—°ë™ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, ìƒˆë¡œìš´ OTT í”Œë«í¼ê³¼ì˜ ì—°ë™ì´ë¯€ë¡œ ì´ˆê¸° ì—°ë™ ì‘ì—…ì´ ë” í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    íŠ¹íˆ, Wrtn TVì˜ ë…ì  ì½˜í…ì¸ ë¥¼ ê°•ì¡°í•˜ëŠ” UI/UX ê°œì„ ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    """

    # ê°œë°œ ê³µìˆ˜ ì˜ˆì¸¡ ì‹¤í–‰
    estimated_mm = estimate_development_effort(new_project_req)

    # ê²°ê³¼ ì¶œë ¥
    display_effort_table(estimated_mm)

